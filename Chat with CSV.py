# -*- coding: utf-8 -*-
"""azure_openai_react.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/amadeus-art/azure-openai-coding-dojo/blob/main/azure_openai_react.ipynb

<a href="https://colab.research.google.com/github/amadeus-art/azure-openai-coding-dojo/blob/main/azure_openai_react.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

# Reasoning + Act: make GPT interact with tools

## Install Depedencies
"""

!pip install langchain
!pip install openai
!pip install python-dotenv

# for serpapi
!pip install google-search-results
# needed to "escape" SSL inside corporate network
!pip install python-certifi-win32

"""## Environment Setup
Before executing the following cells, make sure to set the `AZURE_OPENAI_KEY` and `AZURE_OPENAI_ENDPOINT` variables in the `.env` file or export them.

<br/>
<img src="https://github.com/amadeus-art/azure-openai-coding-dojo/blob/main/assets/keys_endpoint.png?raw=1" width="800"/>
<br/>

In addition, for this notebook we will use Google Search API, which requires an API Key that you can have for free registering with you google email here (100 searches/month): https://serpapi.com

Once you have it, set the `SERPAPI_API_KEY` variable in the `.env` file or export it.
"""

import os
import openai
from dotenv import load_dotenv, find_dotenv

_ = load_dotenv(find_dotenv()) # read local .env file

api_key = os.getenv("AZURE_OPENAI_KEY")
api_base = os.getenv("AZURE_OPENAI_ENDPOINT") # should look like the following https://YOUR_RESOURCE_NAME.openai.azure.com/
deployment = 'gpt-35-dojo'
openai.api_version = '2023-05-15' # may change in the future
openai.api_type = 'azure'

serpapi_api_key = os.getenv('SERPAPI_API_KEY')

from langchain.agents import (
    load_tools,
    initialize_agent,
    AgentType
)

from langchain.chat_models import AzureChatOpenAI

llm = AzureChatOpenAI(
    openai_api_key=api_key,
    openai_api_base=api_base,
    deployment_name=deployment,
    openai_api_version='2023-05-15',
    temperature=0
)

tools = load_tools([
    "serpapi",
    "llm-math",
    ],
    llm=llm,
    serpapi_api_key=serpapi_api_key
)

agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

print(agent.agent.llm_chain.prompt.template)

# run the agent
agent.run("How much is Amadeus IT Group net worth in 2022, raised to the power of 0.678? ")

"""## Add Memory to the Agent
In this section we showcase how to add a buffer memory containing the conversation history to the previous agent. This will allow us to ask follow-up questions having the previous computation into the context.
"""

from langchain.agents import ZeroShotAgent, AgentExecutor
from langchain.chains import LLMChain
from langchain.memory import ConversationBufferMemory

prefix = """Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:"""

# Notice how here we have {chat_history}!
suffix = """Begin!"

{chat_history}
Question: {input}
{agent_scratchpad}"""

prompt = ZeroShotAgent.create_prompt(
    tools,
    prefix=prefix,
    suffix=suffix,
    input_variables=["input", "chat_history", "agent_scratchpad"]
)
memory = ConversationBufferMemory(memory_key="chat_history")

llm_chain = LLMChain(llm=llm, prompt=prompt)
agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)

agent_chain = AgentExecutor.from_agent_and_tools(
    agent=agent,
    tools=tools,
    verbose=True,
    memory=memory
)

print(agent_chain.agent.llm_chain.prompt.template)

agent_chain.run("How much is Amadeus IT Group net worth in 2022, raised to the power of 0.678? ")

agent_chain.run("What is the square root of the last number you computed ?")

agent_chain.run("how many employees does Amadeus IT Group have ? How much is that number multiplied by the answer of the previous square root ?")